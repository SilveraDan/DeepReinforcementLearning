{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-18T22:28:03.056730Z",
     "start_time": "2024-07-18T22:28:03.042160Z"
    }
   },
   "source": [
    "import algorithmes.policy_iteration as pi\n",
    "import algorithmes.sarsa as sa\n",
    "import algorithmes.dyna_q as dq\n",
    "import environnements.lineworld as lw\n",
    "import environnements.gridworld as gw\n",
    "from utils import load_config\n"
   ],
   "outputs": [],
   "execution_count": 18
  },
  {
   "cell_type": "code",
   "id": "4724dc99beb91cbe",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-18T22:28:03.104482Z",
     "start_time": "2024-07-18T22:28:03.091922Z"
    }
   },
   "source": [
    "congig_file = \"config.yaml\""
   ],
   "outputs": [],
   "execution_count": 19
  },
  {
   "cell_type": "markdown",
   "id": "6d0134907eae0680",
   "metadata": {},
   "source": [
    "# LineWorld Environnement"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a6a3c9db55068aa",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Create LineWorld environnement"
   ]
  },
  {
   "cell_type": "code",
   "id": "de8834985fbb2b56",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-18T22:28:03.120103Z",
     "start_time": "2024-07-18T22:28:03.105485Z"
    }
   },
   "source": [
    "config_lineworld = load_config(congig_file, \"LineWorld\")\n",
    "game = \"lineworld\""
   ],
   "outputs": [],
   "execution_count": 20
  },
  {
   "cell_type": "code",
   "id": "7e872c3d22c44f60",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-18T22:28:03.136168Z",
     "start_time": "2024-07-18T22:28:03.120103Z"
    }
   },
   "source": [
    "S = config_lineworld[\"states\"]\n",
    "A = config_lineworld[\"actions\"]\n",
    "R = config_lineworld[\"rewards\"]\n",
    "T = config_lineworld[\"terminals\"]"
   ],
   "outputs": [],
   "execution_count": 21
  },
  {
   "cell_type": "code",
   "id": "81ba099a53929f91",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-18T22:28:03.151792Z",
     "start_time": "2024-07-18T22:28:03.137166Z"
    }
   },
   "source": [
    "lineworld_mdp = lw.create_lineworld(S, A, R)"
   ],
   "outputs": [],
   "execution_count": 22
  },
  {
   "cell_type": "markdown",
   "id": "c7aa5d908c0b6de3",
   "metadata": {},
   "source": [
    "## Dynamic Programming"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d48dd802abcfecc6",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Policy Iteration"
   ]
  },
  {
   "cell_type": "code",
   "id": "c82703c8a3d27776",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-18T22:28:03.167373Z",
     "start_time": "2024-07-18T22:28:03.151792Z"
    }
   },
   "source": [
    "policy, V = pi.policy_iteration(game, lineworld_mdp, S, A, R, T, gamma=0.999)\n",
    "print(\"Optimal Policy:\")\n",
    "print(policy)\n",
    "print(\"Value Function:\")\n",
    "print(V)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 1\n",
      "__X__\n",
      "_X___\n",
      "X____\n",
      "Steps: [2, np.int64(1), np.int64(0)]\n",
      "Total Reward: -1\n",
      "Iteration: 2\n",
      "__X__\n",
      "___X_\n",
      "____X\n",
      "Steps: [2, np.int64(3), np.int64(4)]\n",
      "Total Reward: 1\n",
      "Optimal Policy:\n",
      "[[1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]]\n",
      "Value Function:\n",
      "[0.       0.998001 0.999    1.       0.      ]\n"
     ]
    }
   ],
   "execution_count": 23
  },
  {
   "cell_type": "code",
   "id": "64259603-9d91-40ce-aa48-ef0471add9b1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-18T22:28:03.183041Z",
     "start_time": "2024-07-18T22:28:03.167447Z"
    }
   },
   "source": [
    "# Play the game with the optimal policy\n",
    "steps, total_reward = lw.play_game(policy, lineworld_mdp, R, T)\n",
    "print(f\"Final Steps: {steps}\")\n",
    "print(f\"Final Total Reward: {total_reward}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__X__\n",
      "___X_\n",
      "____X\n",
      "Final Steps: [2, np.int64(3), np.int64(4)]\n",
      "Final Total Reward: 1\n"
     ]
    }
   ],
   "execution_count": 24
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Temporal Difference Learning",
   "id": "e702fd38fcda9cb8"
  },
  {
   "cell_type": "markdown",
   "id": "8c74a0d42d095d4c",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Sarsa\n"
   ]
  },
  {
   "cell_type": "code",
   "id": "fabf293983d54458",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-18T22:28:03.199155Z",
     "start_time": "2024-07-18T22:28:03.183041Z"
    }
   },
   "source": [
    "print(S)\n",
    "print(A)\n",
    "print(R)\n",
    "print(T)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 2, 3, 4]\n",
      "[0, 1]\n",
      "[-1, 0, 1]\n",
      "[0, 4]\n"
     ]
    }
   ],
   "execution_count": 25
  },
  {
   "cell_type": "code",
   "id": "2a861efbabc86931",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-18T22:28:03.215216Z",
     "start_time": "2024-07-18T22:28:03.199155Z"
    }
   },
   "source": [
    "policy, Q = sa.sarsa(game, S, A, R, lineworld_mdp, T, num_episodes=10, gamma=0.999, alpha=0.1, epsilon=0.1, start_state=1)\n",
    "print(\"Optimal Policy:\")\n",
    "print(policy)\n",
    "print(\"Value Function:\")\n",
    "print(Q)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal Policy:\n",
      "[[1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]]\n",
      "Value Function:\n",
      "[[ 0.          0.        ]\n",
      " [-0.19        0.03801564]\n",
      " [-0.00999     0.18670837]\n",
      " [ 0.          0.56953279]\n",
      " [ 0.          0.        ]]\n"
     ]
    }
   ],
   "execution_count": 26
  },
  {
   "cell_type": "code",
   "id": "5c01bc258f9f8ff7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-18T22:28:03.230170Z",
     "start_time": "2024-07-18T22:28:03.216217Z"
    }
   },
   "source": [
    "# Play the game with the optimal policy\n",
    "steps, total_reward = lw.play_game(policy, lineworld_mdp, R, T)\n",
    "print(f\"Final Steps: {steps}\")\n",
    "print(f\"Final Total Reward: {total_reward}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__X__\n",
      "___X_\n",
      "____X\n",
      "Final Steps: [2, np.int64(3), np.int64(4)]\n",
      "Final Total Reward: 1\n"
     ]
    }
   ],
   "execution_count": 27
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Planning",
   "id": "ce9e994aa5bc924e"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Dyna-Q",
   "id": "68b31fc4570cf6e0"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-18T22:28:03.638480Z",
     "start_time": "2024-07-18T22:28:03.230170Z"
    }
   },
   "cell_type": "code",
   "source": [
    "policy, Q = dq.dyna_q(S, A, R, lineworld_mdp, T, n_episodes = 100, n_planning_steps = 100, alpha = 0.1, gamma = 0.999, epsilon = 0.1, start_state = 1)\n",
    "print(\"Optimal Policy:\")\n",
    "print(policy)\n",
    "print(\"Value Function:\")\n",
    "print(Q)"
   ],
   "id": "aa2789242c15b996",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal Policy:\n",
      "[[1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]]\n",
      "Value Function:\n",
      "[[ 0.        0.      ]\n",
      " [-1.        0.998001]\n",
      " [ 0.997003  0.999   ]\n",
      " [ 0.998001  1.      ]\n",
      " [ 0.        0.      ]]\n"
     ]
    }
   ],
   "execution_count": 28
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-18T22:28:03.653304Z",
     "start_time": "2024-07-18T22:28:03.638480Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Play the game with the optimal policy\n",
    "steps, total_reward = lw.play_game(policy, lineworld_mdp, R, T)\n",
    "print(f\"Final Steps: {steps}\")\n",
    "print(f\"Final Total Reward: {total_reward}\")"
   ],
   "id": "4268bd962adec2c1",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__X__\n",
      "___X_\n",
      "____X\n",
      "Final Steps: [2, np.int64(3), np.int64(4)]\n",
      "Final Total Reward: 1\n"
     ]
    }
   ],
   "execution_count": 29
  },
  {
   "cell_type": "markdown",
   "id": "a28e28fb92173b5e",
   "metadata": {},
   "source": [
    "# GridWorld Environnement\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd9d02f4c33a2f48",
   "metadata": {},
   "source": [
    "## Create GridWorld environnement"
   ]
  },
  {
   "cell_type": "code",
   "id": "5ff0e7d510d85cb7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-18T22:28:03.669291Z",
     "start_time": "2024-07-18T22:28:03.653673Z"
    }
   },
   "source": [
    "config_gridworld = load_config(congig_file, \"GridWorld\")\n",
    "game = \"gridworld\""
   ],
   "outputs": [],
   "execution_count": 30
  },
  {
   "cell_type": "code",
   "id": "8dc998b856b23be7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-18T22:28:03.685338Z",
     "start_time": "2024-07-18T22:28:03.669291Z"
    }
   },
   "source": [
    "S = config_gridworld[\"states\"]\n",
    "A = config_gridworld[\"actions\"]\n",
    "R = config_gridworld[\"rewards\"]\n",
    "T = config_gridworld[\"terminals\"]"
   ],
   "outputs": [],
   "execution_count": 31
  },
  {
   "cell_type": "code",
   "id": "c670fb717812da8a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-18T22:28:03.700422Z",
     "start_time": "2024-07-18T22:28:03.685338Z"
    }
   },
   "source": [
    "gridworld_mdp = gw.create_gridworld(S, A, R)"
   ],
   "outputs": [],
   "execution_count": 32
  },
  {
   "cell_type": "markdown",
   "id": "7dff399b071cb583",
   "metadata": {},
   "source": [
    "## Dynamic Programming"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86eeab246465ec52",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Policy Iteration"
   ]
  },
  {
   "cell_type": "code",
   "id": "6829f3af29338fde",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-18T22:28:33.994958Z",
     "start_time": "2024-07-18T22:28:03.701428Z"
    }
   },
   "source": [
    "policy, V = pi.policy_iteration(game, gridworld_mdp, S, A, R, T, gamma=0.999)\n",
    "print(\"Optimal Policy:\")\n",
    "print(policy)\n",
    "print(\"Value Function:\")\n",
    "print(V)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 1\n",
      "_ _ _ _ _\n",
      "_ _ _ _ _\n",
      "_ _ X _ _\n",
      "_ _ _ _ _\n",
      "_ _ _ _ _\n",
      "******************************\n",
      "_ _ _ _ _\n",
      "_ _ X _ _\n",
      "_ _ _ _ _\n",
      "_ _ _ _ _\n",
      "_ _ _ _ _\n",
      "******************************\n",
      "******************************\n",
      "_ _ X _ _\n",
      "_ _ _ _ _\n",
      "_ _ _ _ _\n",
      "_ _ _ _ _\n",
      "_ _ _ _ _\n",
      "******************************\n",
      "Steps: [12, np.int64(7), np.int64(2)]\n",
      "Total Reward: -1\n",
      "Iteration: 2\n",
      "_ _ _ _ _\n",
      "_ _ _ _ _\n",
      "_ _ X _ _\n",
      "_ _ _ _ _\n",
      "_ _ _ _ _\n",
      "******************************\n",
      "_ _ _ _ _\n",
      "_ _ _ _ _\n",
      "_ _ _ _ _\n",
      "_ _ X _ _\n",
      "_ _ _ _ _\n",
      "******************************\n",
      "******************************\n",
      "_ _ _ _ _\n",
      "_ _ _ _ _\n",
      "_ _ _ _ _\n",
      "_ _ _ X _\n",
      "_ _ _ _ _\n",
      "******************************\n",
      "Steps: [12, np.int64(17), np.int64(18)]\n",
      "Total Reward: 1\n",
      "Iteration: 3\n",
      "_ _ _ _ _\n",
      "_ _ _ _ _\n",
      "_ _ X _ _\n",
      "_ _ _ _ _\n",
      "_ _ _ _ _\n",
      "******************************\n",
      "_ _ _ _ _\n",
      "_ _ _ _ _\n",
      "_ _ _ _ _\n",
      "_ _ X _ _\n",
      "_ _ _ _ _\n",
      "******************************\n",
      "******************************\n",
      "_ _ _ _ _\n",
      "_ _ _ _ _\n",
      "_ _ _ _ _\n",
      "_ _ _ X _\n",
      "_ _ _ _ _\n",
      "******************************\n",
      "Steps: [12, np.int64(17), np.int64(18)]\n",
      "Total Reward: 1\n",
      "Optimal Policy:\n",
      "[[1. 0. 0. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [0. 0. 1. 0.]\n",
      " [0. 0. 1. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [1. 0. 0. 0.]]\n",
      "Value Function:\n",
      "[  0.           0.           0.           0.           0.\n",
      "   0.         498.75037595 499.24962657 499.74937695   0.\n",
      "   0.         499.24962657 499.74937695 500.24962757   0.\n",
      "   0.         499.74937695 500.24962757 499.74937794   0.\n",
      "   0.           0.           0.           0.           0.        ]\n"
     ]
    }
   ],
   "execution_count": 33
  },
  {
   "cell_type": "code",
   "id": "ed60895c5a51e044",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-18T22:28:34.009928Z",
     "start_time": "2024-07-18T22:28:33.995959Z"
    }
   },
   "source": [
    "steps, total_reward = gw.play_game(policy, gridworld_mdp, R, T, 6)\n",
    "print(f\"Final Steps: {steps}\")\n",
    "print(f\"Final Total Reward: {total_reward}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_ _ _ _ _\n",
      "_ X _ _ _\n",
      "_ _ _ _ _\n",
      "_ _ _ _ _\n",
      "_ _ _ _ _\n",
      "******************************\n",
      "_ _ _ _ _\n",
      "_ _ _ _ _\n",
      "_ X _ _ _\n",
      "_ _ _ _ _\n",
      "_ _ _ _ _\n",
      "******************************\n",
      "******************************\n",
      "_ _ _ _ _\n",
      "_ _ _ _ _\n",
      "_ _ _ _ _\n",
      "_ X _ _ _\n",
      "_ _ _ _ _\n",
      "******************************\n",
      "******************************\n",
      "_ _ _ _ _\n",
      "_ _ _ _ _\n",
      "_ _ _ _ _\n",
      "_ _ X _ _\n",
      "_ _ _ _ _\n",
      "******************************\n",
      "******************************\n",
      "_ _ _ _ _\n",
      "_ _ _ _ _\n",
      "_ _ _ _ _\n",
      "_ _ _ X _\n",
      "_ _ _ _ _\n",
      "******************************\n",
      "Final Steps: [6, np.int64(11), np.int64(16), np.int64(17), np.int64(18)]\n",
      "Final Total Reward: 1\n"
     ]
    }
   ],
   "execution_count": 34
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Temporal Difference Learning",
   "id": "ddb85cf00a8b6880"
  },
  {
   "cell_type": "markdown",
   "id": "30832f76f8b35ef8",
   "metadata": {},
   "source": [
    "### Sarsa"
   ]
  },
  {
   "cell_type": "code",
   "id": "4b0c572be25f3ffd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-18T22:28:34.056205Z",
     "start_time": "2024-07-18T22:28:34.010251Z"
    }
   },
   "source": [
    "policy, Q = sa.sarsa(game, S, A, R, gridworld_mdp, T, num_episodes=1000, gamma=0.999, alpha=0.1, epsilon=0.1, start_state=6)\n",
    "print(\"Optimal Policy:\")\n",
    "print(policy)\n",
    "print(\"Value Function:\")\n",
    "print(Q)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal Policy:\n",
      "[[1. 0. 0. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [0. 0. 1. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [0. 0. 1. 0.]\n",
      " [0. 0. 1. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [1. 0. 0. 0.]]\n",
      "Value Function:\n",
      "[[ 0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [-0.92023356  0.70268378  0.51792654 -0.96566316]\n",
      " [-0.19        0.76136231  0.          0.08270315]\n",
      " [-0.1         0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.59389261  0.61784818  0.94023923 -0.89058101]\n",
      " [ 0.4243277   0.98250794  0.0522477   0.25557886]\n",
      " [ 0.          0.3439      0.          0.08807178]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.64259192 -0.81469798  0.97702097 -0.81469798]\n",
      " [ 0.76997011 -0.95289871  1.          0.75079807]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]]\n"
     ]
    }
   ],
   "execution_count": 35
  },
  {
   "cell_type": "code",
   "id": "61b485fdf0045241",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-18T22:28:34.072158Z",
     "start_time": "2024-07-18T22:28:34.056205Z"
    }
   },
   "source": [
    "# Play the game with the optimal policy\n",
    "steps, total_reward = gw.play_game(policy, gridworld_mdp, R, T, 6)\n",
    "print(f\"Final Steps: {steps}\")\n",
    "print(f\"Final Total Reward: {total_reward}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_ _ _ _ _\n",
      "_ X _ _ _\n",
      "_ _ _ _ _\n",
      "_ _ _ _ _\n",
      "_ _ _ _ _\n",
      "******************************\n",
      "_ _ _ _ _\n",
      "_ _ _ _ _\n",
      "_ X _ _ _\n",
      "_ _ _ _ _\n",
      "_ _ _ _ _\n",
      "******************************\n",
      "******************************\n",
      "_ _ _ _ _\n",
      "_ _ _ _ _\n",
      "_ _ X _ _\n",
      "_ _ _ _ _\n",
      "_ _ _ _ _\n",
      "******************************\n",
      "******************************\n",
      "_ _ _ _ _\n",
      "_ _ _ _ _\n",
      "_ _ _ _ _\n",
      "_ _ X _ _\n",
      "_ _ _ _ _\n",
      "******************************\n",
      "******************************\n",
      "_ _ _ _ _\n",
      "_ _ _ _ _\n",
      "_ _ _ _ _\n",
      "_ _ _ X _\n",
      "_ _ _ _ _\n",
      "******************************\n",
      "Final Steps: [6, np.int64(11), np.int64(12), np.int64(17), np.int64(18)]\n",
      "Final Total Reward: 1\n"
     ]
    }
   ],
   "execution_count": 36
  },
  {
   "cell_type": "markdown",
   "id": "b28dabed0bbf0154",
   "metadata": {},
   "source": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Planning",
   "id": "9ba42049c0d9524f"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Dyna-Q",
   "id": "69ce5593b4a0d130"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-18T22:28:34.466192Z",
     "start_time": "2024-07-18T22:28:34.072158Z"
    }
   },
   "cell_type": "code",
   "source": [
    "policy, Q = dq.dyna_q(S, A, R, gridworld_mdp, T, n_episodes = 100, n_planning_steps = 100, alpha = 0.1, gamma = 0.999, epsilon = 0.1, start_state = 6)\n",
    "print(\"Optimal Policy:\")\n",
    "print(policy)\n",
    "print(\"Value Function:\")\n",
    "print(Q)"
   ],
   "id": "cbedf513c45a682d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal Policy:\n",
      "[[1. 0. 0. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [0. 0. 1. 0.]\n",
      " [0. 0. 1. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [1. 0. 0. 0.]]\n",
      "Value Function:\n",
      "[[ 0.        0.        0.        0.      ]\n",
      " [ 0.        0.        0.        0.      ]\n",
      " [ 0.        0.        0.        0.      ]\n",
      " [ 0.        0.        0.        0.      ]\n",
      " [ 0.        0.        0.        0.      ]\n",
      " [ 0.        0.        0.        0.      ]\n",
      " [-1.        0.997003  0.997003 -1.      ]\n",
      " [-1.        0.998001  0.998001  0.996006]\n",
      " [-1.        0.999     0.        0.997003]\n",
      " [ 0.        0.        0.        0.      ]\n",
      " [ 0.        0.        0.        0.      ]\n",
      " [ 0.996006  0.996006  0.998001 -1.      ]\n",
      " [ 0.997003  0.997003  0.999     0.997003]\n",
      " [ 0.998001  1.       -1.        0.998001]\n",
      " [ 0.        0.        0.        0.      ]\n",
      " [ 0.        0.        0.        0.      ]\n",
      " [ 0.997003  0.        0.        0.      ]\n",
      " [ 0.998001  0.        0.        0.      ]\n",
      " [ 0.        0.        0.        0.      ]\n",
      " [ 0.        0.        0.        0.      ]\n",
      " [ 0.        0.        0.        0.      ]\n",
      " [ 0.        0.        0.        0.      ]\n",
      " [ 0.        0.        0.        0.      ]\n",
      " [ 0.        0.        0.        0.      ]\n",
      " [ 0.        0.        0.        0.      ]]\n"
     ]
    }
   ],
   "execution_count": 37
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-18T22:28:34.482207Z",
     "start_time": "2024-07-18T22:28:34.466192Z"
    }
   },
   "cell_type": "code",
   "source": [
    "steps, total_reward = gw.play_game(policy, gridworld_mdp, R, T, 6)\n",
    "print(f\"Final Steps: {steps}\")\n",
    "print(f\"Final Total Reward: {total_reward}\")"
   ],
   "id": "618c2beac14c252b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_ _ _ _ _\n",
      "_ X _ _ _\n",
      "_ _ _ _ _\n",
      "_ _ _ _ _\n",
      "_ _ _ _ _\n",
      "******************************\n",
      "_ _ _ _ _\n",
      "_ _ _ _ _\n",
      "_ X _ _ _\n",
      "_ _ _ _ _\n",
      "_ _ _ _ _\n",
      "******************************\n",
      "******************************\n",
      "_ _ _ _ _\n",
      "_ _ _ _ _\n",
      "_ _ X _ _\n",
      "_ _ _ _ _\n",
      "_ _ _ _ _\n",
      "******************************\n",
      "******************************\n",
      "_ _ _ _ _\n",
      "_ _ _ _ _\n",
      "_ _ _ X _\n",
      "_ _ _ _ _\n",
      "_ _ _ _ _\n",
      "******************************\n",
      "******************************\n",
      "_ _ _ _ _\n",
      "_ _ _ _ _\n",
      "_ _ _ _ _\n",
      "_ _ _ X _\n",
      "_ _ _ _ _\n",
      "******************************\n",
      "Final Steps: [6, np.int64(11), np.int64(12), np.int64(13), np.int64(18)]\n",
      "Final Total Reward: 1\n"
     ]
    }
   ],
   "execution_count": 38
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "d4b4fbfb52b6a0d3"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
